{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones en un RDD\n",
    "\n",
    "Los RDDs son inmutables y cada operación crea un nuevo RDD. Las dos operaciones principales que se pueden realizar en una red son transformaciones y acciones:\n",
    "\n",
    "   >-**Transformaciones:** cambian los elementos en el RDD. Algunos ejemplos pueden ser dividir el elemento de entrada, filtrar los elementos y realizar cálculos de algún tipo. Varias transformaciones se pueden realizar en una secuencia, sin embargo, no se lleva a cabo ninguna ejecución durante la planificación. Para las transformaciones spark las agrega al DAC de calculo. DAG proviene de Directed Acyclic Graph y sólo cuando el controlador solicita algunos datos de este DAG realmente se ejecuta; a esto se le llama evaluación perezosa o lazy evaluation.\n",
    "\n",
    "   >-**Acciones:** son operaciones que activan los cálculos. Hasta que se encuentra una operación de acción el plan de ejecución dentro del programa Spark se crea en forma de DAG, por tanto, no se hará nada hasta que se realice una acción dentro del DAG. Podría haber varias transformaciones de todo tipo dentro del plan de ejecución, pero no sucede nada hasta que realicemos una acción. Cualquier tipo de variables que nosotros podamos tener en memoria acelerará grandemente nuestras aplicaciones de Spark, debido a que no se tendrá que ejecutar todo el DAG para reconstruir el RDD que querramos en ese momento.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Tipos de transformaciones\n",
    "\n",
    "Las transformaciones se pueden dividir en cuatro categorías:\n",
    "\n",
    "   >-**Transformaciones generales:** son funciones de transformación que manejan la mayoría de los casos de uso de propósito general. Estas aplican la lógica de transformaciones a los RDD existentes y generan un nuevo RDD de las operaciones comunes de agregación, filtros, etc. Ejemplos: map, filter, flatMap, groupByKey, sortByKey, combineByKey. \n",
    "\n",
    "   >-**Transformaciones matemáticas o estadísticas:** son funciones de transformación que manejan alguna funcionalidad estadística y que generalmente aplican alguna operación matemática o estadística en el RDD existente, generando un nuevo RDD. El muestreo es un gran ejemplo de esto y se usa a menudo en las aplicaciones de spark. Ejemplos: sampleByKey, randomSplit.\n",
    "\n",
    "   >-**Transformaciones de conjunto o relacionales:** son funciones de que manejan transformaciones como uniones de conjuntos de datos y otras funciones algebraicas relacionales como grupo. Funcionan aplicando la lógica de transformación a los RD existentes y generando un nuevo RDD. Ejemplos: cogroup, join, subtractByKey, fullOuterJoin, leftOuterJoin, rightOuterJoin.\n",
    "   \n",
    "   >-**Transformaciones basadas en estructura de datos:** son funciones de transformación que operan en las estructuras de datos subyacentes del RDD, como las particiones por ejemplo. Estas funciones pueden trabajar directamente en particiones sin tocar directamente los elementos o los datos dentro del RDD. Por lo general, las mejoras de rendimiento se pueden realizar redistribuyendo las particiones de datos de acuerdo con el estado del plotter, el tamaño de los datos y los requisitos exactos del caso de uso. Ejemplos: partitionBy, repartition, zipwithIndex, coalesce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función map\n",
    "\n",
    "Map aplica la función de transformación que le proporcionamos a las particiones de entrada para generar particiones de salida en el RDD de salida. Cada partición del RDD da como resultado una nueva partición en un nuevo RDD que esencialmente aplica las transformaciones a todos los elementos del RDD.\n",
    "Se le aplican funciones lamba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un RDD\n",
    "\n",
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con map aplicaremos funciones lambda\n",
    "\n",
    "rdd_resta = rdd.map(lambda x: x - 1)\n",
    "rdd_resta.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, True, False, True, False, True, False]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_par = rdd.map(lambda x: x % 2 == 0)\n",
    "rdd_par.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto = sc.parallelize(['jose', 'juaquin', 'juan', 'lucia', 'karla', 'katia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOSE', 'JUAQUIN', 'JUAN', 'LUCIA', 'KARLA', 'KATIA']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_mayuscula = rdd_texto.map(lambda x: x.upper())\n",
    "rdd_mayuscula.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola jose',\n",
       " 'Hola juaquin',\n",
       " 'Hola juan',\n",
       " 'Hola lucia',\n",
       " 'Hola karla',\n",
       " 'Hola katia']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_hola = rdd_texto.map(lambda x: 'Hola ' + x)\n",
    "rdd_hola.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función flatMap\n",
    "\n",
    "Aplica la función de transformación a las particiones de entrada para generar particiones de salida en el RDD de salida, al igual que la función map. Sin embargo, flatMap también aplana o hace un floating de cualquier colección en los elementos del RDD de entrada.\n",
    "Se le aplican funciones lamba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 4), (3, 9), (4, 16), (5, 25), (6, 36), (7, 49), (8, 64), (9, 81)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aquí el resultado será un RDD con tuplas conteniendo x en la primera posición y x**2 en la segunda\n",
    "rdd_cuadrado = rdd.map(lambda x: (x, x ** 2))\n",
    "rdd_cuadrado.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 4, 3, 9, 4, 16, 5, 25, 6, 36, 7, 49, 8, 64, 9, 81]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Si aplicamos la lambda anterior con flatMap, nos devolverá el resultado sin tuplas, como elementos en una lista\n",
    "rdd_cuadrado_flat = rdd.flatMap(lambda x: (x, x ** 2))\n",
    "rdd_cuadrado_flat.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jose',\n",
       " 'JOSE',\n",
       " 'juaquin',\n",
       " 'JUAQUIN',\n",
       " 'juan',\n",
       " 'JUAN',\n",
       " 'lucia',\n",
       " 'LUCIA',\n",
       " 'karla',\n",
       " 'KARLA',\n",
       " 'katia',\n",
       " 'KATIA']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_mayuscula = rdd_texto.flatMap(lambda x: (x, x.upper()))\n",
    "rdd_mayuscula.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función filter\n",
    "\n",
    "Aplica la función de transformación a las particiones de entrada para generar particiones de salida filtradas en el RDD de salida.\n",
    "Se le aplican funciones lamba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtramos para crear un nuevo RDD que contenga sólo los números pares\n",
    "rdd_par = rdd.filter(lambda x: x % 2 == 0)\n",
    "rdd_par.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtramos para crear un nuevo RDD que contenga sólo los números impares\n",
    "rdd_impar = rdd.filter(lambda x: x % 2 != 0)\n",
    "rdd_impar.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['karla', 'katia']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtramos para crear un nuevo RDD que contenga sólo los nombres que empiecen con k\n",
    "rdd_k = rdd_texto.filter(lambda x: x.startswith('k'))\n",
    "rdd_k.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['juaquin', 'juan']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtramos para crear un nuevo RDD que contenga sólo los nombres que empiecen por j y que su segunda letra sea u\n",
    "rdd_filtro = rdd_texto.filter(lambda x: x.startswith('j') and x.find('u') == 1)\n",
    "rdd_filtro.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función coalesce\n",
    "\n",
    "Aplica una función de transformación a las particiones de entrada para combinar las particiones de entrada en menos particiones en el RDD de salida. Se crea un nuevo RD a partir del RD original, reduciendo a cantidad de particiones y combinándolas según sea necesario. Es una versión optimizada de repartición, donde el movimiento de los datos a través de las particiones es menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos un RDD con 10 particiones\n",
    "rdd_part10 = sc.parallelize([1,2,3.4,5], 10)\n",
    "rdd_part10.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un error habitual es olvidar que los RDD son inmutables, así que si intentas aplicar coalesce al RDD original, no ocurrirá nada\n",
    "rdd_part10.coalesce(5)\n",
    "rdd_part10.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para modificar el número de particiones, habrá que crear un nuevo RDD\n",
    "rdd_part5 = rdd_part.coalesce(5)\n",
    "rdd_part5.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función repartition\n",
    "\n",
    "Aplica una función de transformación a las particiones de entrada para repartir la entrada en menos o más particiones de salida en el RDD de salida. Se crea un nuevo RDD a partir del RDD original, redistribuyendo las particiones, ya sea combinándolas o dividiéndola según sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos un RDD con tres particiones\n",
    "rdd_part3 = sc.parallelize([1,2,3,4,5], 3)\n",
    "rdd_part3.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Incrementamos en número de partiicones a 7\n",
    "rdd_part7 = rdd_part3.repartition(7)\n",
    "rdd_part7.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **punto importante** a tener en cuenta es que repartition y coalesce son operaciones muy costosas ya que mezclan los datos en muchas particiones, por lo tanto intente minimizar el uso de estos tanto como sea posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función reduceByKey\n",
    "\n",
    "Se usa para fusionar los valores de cada clave usando una función asociativa de reducción. Es una transformación de tipo amplia o builder, ya que intercambia datos en múltiples particiones y opera por el par llave-valor. Se hace una reducción por la llave en la partición original y luego se realiza la reducción entre particiones, asignando el resultado a las particiones correspondientes.\n",
    "Requiere una lambda que reciba dos valores, uno para el key y otro para el value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('casa', 2),\n",
       " ('parque', 1),\n",
       " ('que', 5),\n",
       " ('casa', 1),\n",
       " ('escuela', 2),\n",
       " ('casa', 1),\n",
       " ('que', 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos un RDD tipo llave-valor\n",
    "rdd_keyValue = sc.parallelize(\n",
    "    [('casa', 2),\n",
    "     ('parque', 1),\n",
    "     ('que', 5),\n",
    "     ('casa', 1),\n",
    "     ('escuela', 2),\n",
    "     ('casa', 1),\n",
    "     ('que', 1)]\n",
    ")\n",
    "rdd_keyValue.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 6), ('escuela', 2), ('casa', 4), ('parque', 1)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sumamos los values de las keys repetidas\n",
    "rdd_reducido = rdd_keyValue.reduceByKey(lambda x,y: x + y)\n",
    "rdd_reducido.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-IyzVi8nU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
