{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamiento en caché\n",
    "\n",
    "El almacenamiento en caché permite que Spark conserve los datos en todos los cálculos y operaciones.\\\n",
    "Es una de las técnicas más importantes de spark para acelerar los cálculos, especialmente cuando se trata de cálculos interactivos.\\\n",
    "Funciona almacenando el RDD tanto como sea posible en la memoria. Si los datos que se solicitan para almacenar en caché son más grandes que la memoria disponible, el rendimiento disminuirá porque se utilizará disco en lugar de memoria.\n",
    "\n",
    "* Podemos marcar un RDD como almacenado en caché usando **persist()** o **cache()**\n",
    "\n",
    "    * **cache()** es un sinónimo de persist(MEMORY_ONLY)\n",
    "    * **persist()** puede usar memoria, disco o ambos\n",
    "\n",
    "#### Valores posibles para el nivel de almacenamiento\n",
    "\n",
    "* **MEMORY_ONLY** almacena el RDD como un objeto Java deserialización en la JVM. Si el RDD no cabe memoria, algunas particiones no se almacenarán en caché y se volverán a calcular sobre la marcha cada vez que se necesiten. Este es el nivel por defecto en spark.\n",
    "\n",
    "* **MEORY_AND_DISK** almacena los RDD como objetos Java deserializados en la JVM. Si el RDD no cabe en memoria, almacena las particiones que no quepan en el disco y las lee desde allí cuando sea necesario.\n",
    "\n",
    "* **DISK_ONLY** almacena las particiones del RD solo en disco.\n",
    "\n",
    "* **MEMORY_ONLY_2, MEORY_AND_DISK_2, etc** igual que los niveles anteriores, pero replica cada partición en los nodos del cluster.\n",
    "\n",
    "#### ¿Qué nivel de almacenamiento elegir?\n",
    "El nivel de almacenamiento a elegir depende de la situación:\n",
    "\n",
    "* Si los RDD caben en la memoria, use **MEMORY_ONLY**, ya que es la opción más rápida para el rendimiento de ejecución.\n",
    "\n",
    "* **DISK_ONLY** no debe usarse a menos que sus cálculos sean costosos.\n",
    "\n",
    "*  Utilice almacenamiento replicado para una mejor tolerancia fallos si puede ahorrar la memoria adicional necesaria. Esto evitará que se vuelvan a calcular las particiones perdidas para obtener la mejor disponibilidad.\n",
    "\n",
    ">Podemos usar la función **unpersist()** para liberar el contenido en cahé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([item for item in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\\\n",
    ">Si quisiéramos cambiar el nivel de persistencia al mismo RDD, debemos tener en cuenta que primero es necesario hacerle **unpersist()** a este mismo RDD. De lo contrario, si tratamos de cambiarle el nivel de persistencia sin realizar esta acción, nos va a devolver un error.\n",
    ">\n",
    "><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.unpersist()\n",
    "\n",
    "rdd.persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.unpersist()\n",
    "# Cuando le aplicamos cache(), estamos haciendo un MEMORY_ONLY\n",
    "rdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition y shuffling (mezcla de datos)\n",
    "\n",
    "* Los RDD operan con datos no como una sola masa de datos, sino que administran y operan los datos en particiones repartidas por todo el cluster. Por lo tanto, el concepto de partición de datos es fundamental para el correcto funcionamiento de los chop de Apache spark y puede tener un gran efecto en el rendimiento y en la forma en que se utilizan los recursos.\n",
    "\n",
    "* Los RDD constan de particiones de datos y todas las operaciones se realizan en las particiones de datos en el RDD. Algunas operaciones, como las **transformaciones**, son funciones ejecutadas por un ejecutor en la partición específica de datos en la que se opera. Sin embargo, no todas las operaciones pueden realizarse simplemente realizando operaciones aisladas en las particiones de datos por parte de los respectivos ejecutores Las operaciones como las **agregaciones**, requieren que los datos se muevan a través del cluster en una fase conocida como mezcla o **shuffle**.\n",
    "\n",
    "#### Importancia del número de particiones\n",
    "\n",
    "* Si la cantidad de particiones es demasiado pequeña, usaremos sólo unas pocas CPU o núcleos en una gran cantidad de datos, por lo que tendremos un rendimiento más lento y dejaremos el cluster subutilizado.\n",
    "\n",
    "* Si la cantidad de particiones es demasiado grande, utilizará más recursos de los que realmente necesita y en un entorno de múltiples procesos, podría estar provocando la falta de recursos para otros procesos que usted u otros miembros de su equipo ejecutan.\n",
    "\n",
    "#### Particionadores\n",
    "\n",
    "El particionamiento de los RDD se realiza mediante patinadores. Los patinadores asignan un índice de partición a los elementos del RDD. Todos los elementos de la misma partición tendrán el mismo índice de partición.\\\n",
    "Spark dispone de dos patinadores el HashPartitioner y el RangePartitioner.\n",
    "Además de esto, también puede implementar un patrocinador personalizado.\n",
    "\n",
    "* **HashPartitioner:** es el patrocinador predeterminado en spark y funciona calculando un valor hash para cada clave de los elementos. Todos los elementos con el mismo código hash terminan en una misma partición y esto se hace utilizando la fórmula siguiente:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partitionIndex = hash(key) % numPartitions\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;El partitionIndex es iguel al hash del elemento dividido entre el número de particiones\n",
    "\n",
    "* **RangePartitioner:** funciona dividiendo el RDD en rangos aproximadamente iguales. Dado que el rango debe conocer las claves de inicio y final de cualquier partición, el RDD debe ordenarse primero antes de que se pueda usar un RangePartitioner. RangePartitioner primero necesita límites razonables para las particiones basadas en el RDD, luego crea una función desde la clave K hasta el partitionIndex al que pertenece el elemento y finalmente necesitamos reparticionar el RDD, basado en el RangePartitioner y para redistribuir los elementos del RDD correctamente según los rangos que determinamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veamos en la práctica cómo podemos implementar un **HashPartitioner** manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize(['x', 'y', 'z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hola = 'Hola'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514654146388779058"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos el valor hash de la variable hola\n",
    "hash(hola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particiones = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# indice = hash(item) % num_particiones\n",
    "\n",
    "print(hash('x') % num_particiones)\n",
    "\n",
    "print(hash('y') % num_particiones)\n",
    "\n",
    "print(hash('z') % num_particiones)\n",
    "\n",
    "# Aquí podemos ver a qué partición irá cada valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling (mezcla de datos)\n",
    "\n",
    "Cualquiera que sea el participio utilizado, muchas operaciones provocarán un reparticionamiento de datos en las particiones de un RDD. Se pueden crear nuevas particiones o se pueden contraer o fusionar varias particiones.\n",
    "\n",
    "Todo el movimiento de datos necesario para el reparto se denomina **shuffling** y este es un concepto importante que hay que comprender al escribir un job de Spark.\n",
    "\n",
    "El shuffling puede causar un gran impacto en el rendimiento, ya que los cálculos ya no están en la memoria del mismo ejecutor, sino que los ejecutores están intercambiando datos a través de la red.\n",
    "\n",
    "Cuando un RDD está experimentando una transformación, se intenta que las operaciones que se realicen en el mismo nodo que los datos. Sin embargo, a menudo utilizamos operaciones de unión, reducción, agrupación o agregación, entre otras, que provocan el shuffling intencionado o no intencionado.\n",
    "\n",
    "Este shuffle, a su vez, determina dónde ha finalizado una etapa particular del procesamiento y donde ha comenzado una nueva.\n",
    "\n",
    ">\\\n",
    ">Cuanto más suffling tengamos, más etapas o stages ocurren en la ejecución del Job que afecta el rendimiento. Por lo tanto, estos temas debemos tenerlos en cuenta a la hora de construir de nuestros Jobs de Spark.\n",
    ">\n",
    "><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast variables\n",
    "\n",
    "Las variables broadcast son variables compartidas entre todos los ejecutores. Éstas se crean una vez en el controlador y luego se leen sólo en los ejecutores.\n",
    "\n",
    "Se pueden transmitir conjuntos de datos completos en un cluster de Spark para que los ejecutores tengan acceso a los datos transmitidos. Todas las tareas que se ejecutan dentro de un ejecutor tienen acceso a las variables broadcast.\n",
    "\n",
    "Lo que sucede al crear una variable broadcast es que la información de esta variable estará disponible en todos los **worker nodes** y será posible acceder a los datos de esta misma variable broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uno = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una variable broadcast llamando a la función broadcast del sparl context\n",
    "br_uno = sc.broadcast(uno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a sumar al primer rdd que creamos el valor de la variable broadcast, llamándola con .value\n",
    "rdd3 = rdd.map(lambda x: x + br_uno.value)\n",
    "\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\\\n",
    ">Las variables broadcast ocupan memoria en todos los ejecutores y según el tamaño de los datos contenidos en la variable broadcast, estos puede causar problemas de recursos en algún momento.\n",
    ">\n",
    "><br>\n",
    "\n",
    "Existe una forma de eliminar las variables de la memoria de todos los ejecutores.\n",
    "Para ello, lo que vamos a hacer es llamar a la función **unpersist()** en una variable que previamente lavtengamos como broadcast y esto lo que va a hacer es eliminar los datos de la variable broadcast de la memoria de caché de todos los ejecutores para así liberar recursos.\n",
    "\n",
    "Si la variable se volviera a utilizar los datos se retransmitirían a los ejecutores para que se vuelvan a utilizar.\n",
    "\n",
    "Tenemos que tener en cuenta que después de llamar a unpersist(), si accedemos a la variable broadcast nuevamente funciona como de costumbre, es decir, por detrás de escena los executors están extrayendo los datos de la variable nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al aplicar unpersist() retiramos la variable de los executors\n",
    "br_uno.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si volvemos a llamar a la broadcast variable a la que le acabamos de aplicar el unpersist(), se ejecuta sin ningún tipo de problema\n",
    "rdd4 = rdd.map(lambda x: x + br_uno.value)\n",
    "\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\\\n",
    ">Para eliminar completamente una variable broadcast, hay que eliminarla de todos los executors y del driver con la función **destroy()**\n",
    ">\n",
    ">Esto puede resultar muy útil para administrar los recursos de manera óptima en todo el cluster.\n",
    ">\n",
    "><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destroy()  destruye todos los datos y metadatos relacionados con la variable broadcast especificada.\n",
    "br_uno.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/18 11:36:47 ERROR Utils: Exception encountered\n",
      "org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n",
      "\tat org.apache.spark.broadcast.Broadcast.assertValid(Broadcast.scala:144)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeObject$1(TorrentBroadcast.scala:243)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1495)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.writeObject(TorrentBroadcast.scala:242)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n",
      "\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat java.util.ArrayList.writeObject(ArrayList.java:768)\n",
      "\tat sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n",
      "\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n",
      "\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n",
      "\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n",
      "\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1525)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.io.IOException: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \njava.io.IOException: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1502)\n\tat org.apache.spark.broadcast.TorrentBroadcast.writeObject(TorrentBroadcast.scala:242)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat java.util.ArrayList.writeObject(ArrayList.java:768)\n\tat sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1525)\n\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.broadcast.Broadcast.assertValid(Broadcast.scala:144)\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeObject$1(TorrentBroadcast.scala:243)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1495)\n\t... 40 more\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1545)\n\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1502)\n\tat org.apache.spark.broadcast.TorrentBroadcast.writeObject(TorrentBroadcast.scala:242)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat java.util.ArrayList.writeObject(ArrayList.java:768)\n\tat sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1525)\n\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.broadcast.Broadcast.assertValid(Broadcast.scala:144)\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeObject$1(TorrentBroadcast.scala:243)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1495)\n\t... 40 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Si ahora intentamos volver a acceder a la variable broadcast, nos arrojará un error\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rdd5  \u001b[39m=\u001b[39m rdd\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: x \u001b[39m+\u001b[39m br_uno\u001b[39m.\u001b[39mvalue)\n\u001b[0;32m----> 4\u001b[0m rdd5\u001b[39m.\u001b[39;49mtake(\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pyspark-IyzVi8nU/lib/python3.10/site-packages/pyspark/rdd.py:2836\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   2833\u001b[0m         taken \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   2835\u001b[0m p \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(partsScanned, \u001b[39mmin\u001b[39m(partsScanned \u001b[39m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 2836\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49mrunJob(\u001b[39mself\u001b[39;49m, takeUpToNumLeft, p)\n\u001b[1;32m   2838\u001b[0m items \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m res\n\u001b[1;32m   2839\u001b[0m partsScanned \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pyspark-IyzVi8nU/lib/python3.10/site-packages/pyspark/context.py:2319\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   2317\u001b[0m mappedRDD \u001b[39m=\u001b[39m rdd\u001b[39m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[1;32m   2318\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2319\u001b[0m sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonRDD\u001b[39m.\u001b[39;49mrunJob(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsc\u001b[39m.\u001b[39;49msc(), mappedRDD\u001b[39m.\u001b[39;49m_jrdd, partitions)\n\u001b[1;32m   2320\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[39m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pyspark-IyzVi8nU/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pyspark-IyzVi8nU/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    170\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pyspark-IyzVi8nU/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.io.IOException: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \njava.io.IOException: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1502)\n\tat org.apache.spark.broadcast.TorrentBroadcast.writeObject(TorrentBroadcast.scala:242)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat java.util.ArrayList.writeObject(ArrayList.java:768)\n\tat sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1525)\n\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.broadcast.Broadcast.assertValid(Broadcast.scala:144)\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeObject$1(TorrentBroadcast.scala:243)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1495)\n\t... 40 more\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1545)\n\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1502)\n\tat org.apache.spark.broadcast.TorrentBroadcast.writeObject(TorrentBroadcast.scala:242)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat java.util.ArrayList.writeObject(ArrayList.java:768)\n\tat sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1525)\n\tat org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1353)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2931)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: Attempted to use Broadcast(0) after it was destroyed (destroy at NativeMethodAccessorImpl.java:0) \n\tat org.apache.spark.broadcast.Broadcast.assertValid(Broadcast.scala:144)\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeObject$1(TorrentBroadcast.scala:243)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1495)\n\t... 40 more\n"
     ]
    }
   ],
   "source": [
    "# Si ahora intentamos volver a acceder a la variable broadcast, nos arrojará un error\n",
    "rdd5  = rdd.map(lambda x: x + br_uno.value)\n",
    "\n",
    "rdd5.take(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-IyzVi8nU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
